# LLM Attack Simulation Lab ðŸ”¬

Un laboratoire interactif pour comprendre et simuler les attaques sur les Large Language Models (LLMs).

## Objectif

Ce lab permet de:
- **Comprendre** les vulnÃ©rabilitÃ©s des LLMs
- **Simuler** diffÃ©rents types d'attaques en environnement contrÃ´lÃ©
- **Apprendre** les mÃ©canismes de dÃ©fense

## Types d'attaques simulÃ©es

| Attaque | Description | Risque |
|---------|-------------|--------|
| **Prompt Injection** | Manipulation des instructions du LLM | Critique |
| **Data Poisoning** | Corruption des donnÃ©es d'entraÃ®nement | Ã‰levÃ© |
| **Jailbreak** | Contournement des guardrails | Critique |
| **Model Extraction** | Vol de propriÃ©tÃ© intellectuelle | Ã‰levÃ© |
| **Membership Inference** | DÃ©tection de donnÃ©es d'entraÃ®nement | Moyen |

## Installation

```bash
# Cloner le repository
git clone <repo-url>
cd iattack

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le lab
python -m llm_attack_lab
```

## Utilisation

### Mode CLI Interactif
```bash
python -m llm_attack_lab --interactive
```

### Mode Dashboard Web
```bash
python -m llm_attack_lab --web
# Ouvrir http://localhost:8080
```

### ExÃ©cuter une simulation spÃ©cifique
```bash
python -m llm_attack_lab --attack prompt_injection
python -m llm_attack_lab --attack data_poisoning
python -m llm_attack_lab --attack jailbreak
```

## Structure du Projet

```
llm_attack_lab/
â”œâ”€â”€ __main__.py           # Point d'entrÃ©e
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_simulator.py  # Simulateur de LLM
â”‚   â””â”€â”€ attack_engine.py  # Moteur d'attaques
â”œâ”€â”€ attacks/
â”‚   â”œâ”€â”€ prompt_injection.py
â”‚   â”œâ”€â”€ data_poisoning.py
â”‚   â”œâ”€â”€ jailbreak.py
â”‚   â””â”€â”€ model_extraction.py
â”œâ”€â”€ defenses/
â”‚   â”œâ”€â”€ input_sanitizer.py
â”‚   â””â”€â”€ output_filter.py
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ templates/
â””â”€â”€ utils/
    â””â”€â”€ logger.py
```

## Avertissement

Ce laboratoire est destinÃ© Ã  des fins **Ã©ducatives uniquement**.
L'utilisation de ces techniques sur des systÃ¨mes sans autorisation est illÃ©gale.

## Licence

MIT License - Usage Ã©ducatif uniquement
